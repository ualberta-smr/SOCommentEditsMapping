# Overview
This project analyzes crowd-sourced answers on Stack Overflow to determine a relationship between comments and edits on an answer. It does this by looping through the comments and edits on an answer and uses regular expressions to identify common code terms in order to determine whether a comment caused an edit. This repository contains the source code for matching comments to edits, as well as our results of analyzing five Stack Overflow tags (`Java`, `Javascript`, `Android`, `Php`, and `Python`) as per our EMSE Submission titled "Can We Use Stack Overflow as a Source of Explainable Bug-fix Data?" by Henry Tang and Sarah Nadi.

# Instructions
The following is the set of instructions needed to run this project.

## Prerequisites
The program is written in Python 3.6.8. You need sqlite3 V3.25 if you are using the source code as is. If using a lower sqlite3 version, then there are comments in the source code that detail what to change.

This program assumes there is a copy of the SOTorrent dataset in a SQLite database named *sotorrent.sqlite3* located at the root of the project. The dataset used for this project is the SOTorrent version: Version 2019-09-23 linked [here](https://zenodo.org/record/3460115).

We used existing scripts from the [sotorrent-sqlite3 GitHub repo](https://github.com/awwong1/sotorrent-sqlite3) to create an SQLite database from the SOTorrent data, as the instructions provided with the SOTorrent dump create a MySQL database. This repo contains two scripts: 

* `get_and_verify_all.sh` which is used to download the *.xml.gz and *.csv.gz files of Version 2018-12-09 of the SOTorrent dump from [zenodo](https://zenodo.org/record/3460115) OR the user can download the version of SOTorrent they want manually (this project uses Version 2019-09-23). 

* `main.py` is what is used to create an sqlite database called *sotorrent.sqlite3* and populate it with the data in the SOTorrent dump. Note that this process takes ~2 days.

The program requires the following Python libraries:
* [Pandas](https://pandas.pydata.org/) v0.24.2
* [Matplotlib](https://matplotlib.org/) v3.1.0
* [Fuzzywuzzy](https://github.com/seatgeek/fuzzywuzzy) v0.17.0
    * [python-Levenshtein]() v0.12.0
* [NumPy](https://numpy.org/) v1.16.4

These dependencies can all be installed by running `pip3 install [library-name]` or using the `requirements.txt` file provided with `pip3 install -r requirements.txt`

## Running
The program can be run in the root directory of the project with the command `python3 src/main.py`

This program has multiple command line options:

`--clean` or `-c` has two values: `True` or `False`
* True is the **default** vale for this option. This option tells the program to **clean (delete) and create** the necessary SQL tables for the program to run.
* False will tell the program to assume the necessary tables are present and the SQL scripts in the *sql/* folder will not run.

`--type` or `-t` has two values: `Full` or `Stats`
* `Full` is the **default** value for this option. This option tells the program to run the full analysis. This means the program will retrieve the data needed from the dataset and generate the full results file (stored as **results.csv**), bubble plot of comment-edit distribution, and general statistics. The program will also generate the tag-specific result files (containing only matched comment-edit pairs), a statistics text file that is split by StackOverflow tag, and a graph that shows the distribution of answer scores for each tag.
* `Stats` tells the program to only generate the tag-specific result files, the statistics text file split by Stack Overflow tag, and the answer score distribution graphs. This will only work if a **results.csv** file (generated by a previous *Full* run) is present in the root directory.

`--user` or `-u` has two values: `True` or `False`
* `True` allows comments and edits to be matched by the same author. i.e., if a user makes a comment and then makes the edit themselves. 
* `False` is the **default** value for this option. We found that generally comments and edits with the same author that are matched do not tend to be useful. Therefore to reduce the amount of noise we set this option default False.

`--naive` or `-n` has two values: `True` or `False`
* `Tru`e tells the program to naively pair comments and edits on a temporal basis alone. It matches a comment with the closest temporal edit. This is the baseline we use for comparison in Table 2 of the paper in subsection *Automatically Matching Comments and Edits*
* `False` is the **default** value as comment-edit pair matching based on time is not accurate.

`--eval` or `-e` has two values: `True` or `False`
* `True` tells the program to evaluate itself against a given `ground_truth.csv`. 
    * A sample `ground_truth.csv` is provided under the `data` directory. The `ground_truth.csv` requires three columns: `EditIds`, `EditGroups`, and `Useful`. `EditIds` are the manual evaluations of which comments and edits are paired. `EditGroups` are the comment-edit pairs the program returned on a previous run on of the program. `Useful` is a column containing the manual evaluations of whether the comment-edit pair is useful. This should be denoted by the word `yes`. 
    * If this flag is set to `True`, the program will only run the evaluation and will not run any other parts of the program (this uses the values in the `ground_truth.csv` under the `EditGroups` column retrieved from a previous run of the program and it does not re-match pairs)
* False is the **default** value.

## Regular expression patterns

The list of regular expression patterns we used is located in `src/regex_patterns.py` at the top of the file.

## SQL scripts

There are two sql scripts that are required by the program.

* `EditHistory.sql`

    This script is used to create the EditHistory table. This table aggregates the events (the initial body, body edits, and comments) of every question and answer with the event's creation date. This tables allows us to see a chronological history of each question and answer. 

* `EditHistory_Code.sql`

    This script creates the EditHistory_Code table. This table is similar to the EditHistory table. However, it does not store questions and question history, it only stores answers and answer history, and comments. The answers and answer histories also only store the code changes for each edit.

# Results

Our results of running the program on the five tags (java, javascript, php, Android, and Python) on SOTorrent version 2019-09-23 project are located [here](). This file also includes the database tables used.

The extracted zip folder will contain multiple directories and files. These directories and files are described below.
To import the csvs into an sqlite3 database follow the steps in the **Importing** section

1. The `database_tables` directory contains the CSV's of the database tables (generated by exporting the tables from sqlite3) needed for the program to run its analysis:

    * `QuestionIds.csv`
        
        This file contains the question ids of each of the five tags used. 

    * `AnswerIds.csv`
        
        This file contains the answer ids of each of the five tags used. They can be used to modify the queries in the code to isolate and focus on a specific tag. e.g., `SELECT * FROM EditHistory_Code WHERE Event = 'InitialBody' AND PostId IN (SELECT Id from AnswerIds WHERE Tag = 'Java');`

    * `EditHistory_Code.csv`

        This table is what is used by the program to analyze comments and edits on answers. This table contains the answers, answer history, and comments that were analyzed by the program.

    * `EditHistory.csv`

        This table is the aggregation of all questions, answers, and their histories and comments. This table is used predominantly for the creation of the EditHistory_Code table, but is also used to retrieve the question id.
    
Additionally the `PostBlockVersion.csv`, `PostHistory.csv`, `Posts.csv`, `PostVersion.csv`, and `Users.csv` files are provided if you wish to create the `EditHistory` and `EditHistory_Code` tables without wanting to download the entire SOTorrent dump.

2. The `results` directory contains the results of running the program on each tag separately:

    * `<tag>_results.csv`

        These five files are the complete results of running the program on the individual tags. There are many rows in the csvs and to view the entire results will most likely require the importing of the csvs into a database table. 
       
    * `<tag>_stats.txt`
    
        These five files are some descriptive statistics for each tag.

3. The `ground_truth` directory contains the files used to determine the ground truth in the *Extracting Comment-Edit Pairs* section of the paper: 

    * `<tag>.csv`

        These five csv files are the results of the authors' ground truth analysis of comments for 20 questions in each of the focused tags. The *Resolution* column are the edit ids agreed upon by the authors. This table is used in the *Comparison with Ground Truth* subsection or the *Mapping Comments to Edits* section of the paper

4. The `general_precision` directory contains files used in answering the 4 research questions in sections *Precision of Comment-Edit Pairs*, *Tangled Changes*, *Types of Changes in Comment-Edit Pairs*, and *Usefulness of Comment-Edit Pairs* of the paper:

    * `<tag>.csv`
    
        These five files are the raw analysis of both authors. Each file contains the 382 randomly sampled pairs for that tag and details the initial analysis of each author as well as the resolutions of any disagreements. The analysis includes the initial categories assigned, the usefulness, and tangledness of the comment-edit pairs.

    * `kappa_stats_by_tag.csv` 

        This file details the calculations for the Cohen's Kappa coefficient for each tag. This is used to create tables 4 and 5 of the paper.
        
    * `kappa_stats_by_category.csv` 

        This file details the calculations for the Cohen's Kappa coefficient for each category. This was used for section `RQ3: Types of Changes in Comment-Edit Pairs`

    * `stats.csv` 

        This file contains the statistics of each tag and category. It describes the number of confirmed comment-edit pairs for each category for each type, as well as their usefulness and tangledness. This is used to create table 7 of the paper.
        
    * `categories.csv` 

        This file details our coding guide used in categorizing each comment-edit pair. It contains the archetypes of comments we find and how they fit into the relevant originally published [TSE](https://petertsehsun.github.io/papers/so_comment_empirical_tse2020.pdf) categories. Some notes are provided on how we determined whether a comment fit into a category or not.
        
5. The `pull_requests.csv` file contains the details of the 15 comment-edit pairs we used to make pull requests on open source repositories. The file details which part of the edit was used as well as how the comment was paraphrased (if it was) on the pull request. The links to the repositories and pull requests have also been provided.

## Importing

To import csvs into an sqlite3 database follow these steps:

1. Start sqlite3 with an empty database using `sqlite3 <database_name>.sqlite3`

2. Create tables to store the data in the csvs. You can write a *.sql file and run it in sqlite using `.read path-to-script`
    * The EditHistory and EditHistory_Code schemas are already provided in the `sql/EditHistory.sql` and `sql/EditHistory_Code.sql` files

3. Change the read mode of sqlite3 by using `.mode csv`

4. Import the csvs by runnning `.import "path-to-csv" <table-name>`

# Contributors

* Henry Tang <hktang@ualberta.ca>

* Sarah Nadi <nadi@ualberta.ca>

# License
Described in the  LICENSE file 
